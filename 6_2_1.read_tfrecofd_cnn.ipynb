{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd '/content/gdrive/My Drive/TensorFlow_Training_12th'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training에 사용할 image size\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tfrecord file 이름과 디렉토리 설정\n",
    "tfrecord_train = 'simpsons_small_train.tfrecord'\n",
    "tfrecord_test = 'simpsons_small_test.tfrecord'\n",
    "tfrecord_dir = 'tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tfrecord file 경로 설정\n",
    "cur_dir = os.getcwd()\n",
    "train_tfr_path = os.path.join(cur_dir, tfrecord_dir, tfrecord_train)\n",
    "test_tfr_path = os.path.join(cur_dir, tfrecord_dir, tfrecord_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper parameters\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 30\n",
    "batch_size = 16\n",
    "\n",
    "## class 갯수\n",
    "n_class = 12\n",
    "## training data 수\n",
    "n_train = 7488\n",
    "## test data 수\n",
    "n_test = 2496\n",
    "## learning rate decay ratio\n",
    "lr_decay_ratio = 0.1\n",
    "## 몇 epoch 마다 learning rate을 decay할 것인지\n",
    "lr_decay_epoch_num = 10\n",
    "## image file 위치\n",
    "image_dir = 'simpsons_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(tfrecord_serialized):\n",
    "    features={'image': tf.FixedLenFeature([], tf.string),\n",
    "             'label': tf.FixedLenFeature([], tf.int64)}\n",
    "    parsed_features = tf.parse_single_example(tfrecord_serialized, features)\n",
    "    \n",
    "    image = tf.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [img_height, img_width, 3])\n",
    "    image = tf.cast(image, tf.float32)/255.\n",
    "    \n",
    "    label = tf.cast(parsed_features['label'], tf.int32)\n",
    "    label = tf.one_hot(label, depth=n_class)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_tfr_path)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=8)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=n_train*2).prefetch(\n",
    "    buffer_size=batch_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.TFRecordDataset(test_tfr_path)\n",
    "test_dataset = test_dataset.map(_parse_function, num_parallel_calls=8)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=n_train*2).prefetch(\n",
    "    buffer_size=batch_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Dense, ReLU, BatchNormalization, MaxPool2D, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(img_height, img_width, 3))\n",
    "    ## build your model!\n",
    "    net = inputs\n",
    "    return keras.Model(inputs=inputs, outputs=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images, training=True)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=logits, labels=labels))    \n",
    "    return loss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    return tape.gradient(loss, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, images, labels):\n",
    "    logits = model(images, training=False)\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_test_acc = 0.\n",
    "    train_step = 0\n",
    "    test_step = 0\n",
    "    \n",
    "    for images, labels in train_dataset:\n",
    "        #print(images.shape, labels.shape)\n",
    "        images = tf.image.resize(images, (img_height, img_width)) \n",
    "        grads = grad(model, images, labels)                \n",
    "        optimizer.apply_gradients(zip(grads, model.variables))\n",
    "        loss = loss_fn(model, images, labels)\n",
    "        acc = evaluate(model, images, labels)\n",
    "        avg_loss = avg_loss + loss\n",
    "        avg_train_acc = avg_train_acc + acc\n",
    "        train_step += 1\n",
    "    avg_loss = avg_loss / train_step\n",
    "    avg_train_acc = avg_train_acc / train_step\n",
    "    \n",
    "    for images, labels in test_dataset:\n",
    "        images = tf.image.resize(images, (img_height, img_width)) \n",
    "        acc = evaluate(model, images, labels)        \n",
    "        avg_test_acc = avg_test_acc + acc\n",
    "        test_step += 1    \n",
    "    avg_test_acc = avg_test_acc / test_step    \n",
    "\n",
    "    print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), \n",
    "          'train accuracy = ', '{:.4f}'.format(avg_train_acc), \n",
    "          'test accuracy = ', '{:.4f}'.format(avg_test_acc))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = cur_dir\n",
    "image_path = os.path.join(data_dir, image_dir)\n",
    "\n",
    "class_names = sorted(os.listdir(image_path))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    #plt.xticks([])\n",
    "    plt.xticks(range(n_class), class_names, rotation=90)\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(n_class), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1]) \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    " \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rnd_idx = np.random.randint(1, n_test//batch_size)\n",
    "img_cnt = 0\n",
    "for images, labels in test_dataset:\n",
    "    img_cnt += 1\n",
    "    if img_cnt != rnd_idx:\n",
    "        continue\n",
    "    predictions = keras.activations.softmax(model(images, training=False))    \n",
    "    num_rows = 8\n",
    "    num_cols = 2\n",
    "    num_images = num_rows*num_cols\n",
    "    labels = tf.argmax(labels, axis=-1)\n",
    "    plt.figure(figsize=(3*3*num_cols, 7*num_rows))\n",
    "    plt.subplots_adjust(hspace=1.0)\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "        plot_image(i, predictions.numpy(), labels.numpy(), images.numpy())\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "        plot_value_array(i, predictions.numpy(), labels.numpy())        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
